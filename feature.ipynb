{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "## Jun. 6\n",
    ">Status\n",
    "1. By now, the best regressor is simple LassoCV using CV = 5\n",
    "2. For categorical feature, use OneHot encoder.\n",
    "3. The features having unique values, are dropped.\n",
    "4. Try box-cox change of Y, but no imporvement.\n",
    "\n",
    ">TODO\n",
    "1. More work on feature engineering, try to reduce the dimension:\n",
    " + PCA\n",
    " + delete the dimensions with small variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_y = train_df.y\n",
    "train_x = train_df.drop(['ID','y'],axis = 1)\n",
    "test_df = pd.read_csv('test.csv')\n",
    "test_x =  test_df.drop(['ID'],axis = 1)\n",
    "cat_cols = train_x.select_dtypes(['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "## Issue: Categorical value of train and test are different\n",
    "Sol:  try to change the catogorical data in test set to values existant in training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for col in cat_cols:\n",
    "#    print col, set(test_df[col].unique()).difference(set(train_x[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x0_tran = {'ae':'ad', 'ag':'af','bb':'ba','an':'am','p':'r','av':'aw'}\n",
    "#x2_tran = {'ab':'ac', 'ad':'ae', 'aj':'ai', 'u':'t', 'w':'x', 'ax':'ay'}\n",
    "#x5_tran = {'a':'aa', 'b':'c', 't':'r', 'z':'y'}\n",
    "\n",
    "#test_x['X0'] = map(lambda x: x0_tran[x] if x in x0_tran.keys() else x, test_x['X0'])\n",
    "#test_x['X2'] = map(lambda x: x2_tran[x] if x in x2_tran.keys() else x, test_x['X2'])\n",
    "#test_x['X5'] = map(lambda x: x5_tran[x] if x in x5_tran.keys() else x, test_x['X5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# fit the Label binarizer\n",
    "lbs = list()\n",
    "for col in cat_cols:\n",
    "    lb = LabelBinarizer().fit(train_x[col])\n",
    "    lbs.append(lb)\n",
    "\n",
    "# transform the trianing set\n",
    "for col, lb in zip(cat_cols,lbs):\n",
    "    bina_df = pd.DataFrame(lb.transform(train_x[col]),\n",
    "                           columns= map(lambda x: col + '_' + str(x), range(len(lb.classes_))))\n",
    "    train_x = pd.concat([train_x, bina_df], axis=1)\n",
    "\n",
    "# transform the test set    \n",
    "for col,lb in zip(cat_cols, lbs):\n",
    "    bina_df = pd.DataFrame(lb.transform(test_x[col]),\n",
    "                           columns= map(lambda x: col + '_' + str(x), range(len(lb.classes_))))\n",
    "    bina_df.loc[bina_df.sum(axis = 1) == 0] =1./len(lb.classes_)\n",
    "    test_x = pd.concat([test_x, bina_df], axis=1)\n",
    "# drop the categorical data\n",
    "train_x.drop(cat_cols, axis =1, inplace=True)\n",
    "test_x.drop(cat_cols, axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 563) (4209, 563)\n"
     ]
    }
   ],
   "source": [
    "print train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop features which are collineare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if all the values are the same, then drop all\n",
    "for col in [col  for col in train_x.columns if len(np.unique(train_x[col]))==1 ]:\n",
    "    train_x.drop(col, axis = 1, inplace= True)\n",
    "    test_x.drop(col, axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 478) (4209, 478)\n"
     ]
    }
   ],
   "source": [
    "train_corr = train_x.corr()\n",
    "colli = list()\n",
    "for col in range(train_corr.shape[0]):\n",
    "    for index in range(col):\n",
    "        if train_corr.iloc[index, col] == 1:\n",
    "            colli.append([index, col])\n",
    "def get_group(collis):\n",
    "    groups = list()\n",
    "    for coll in colli:\n",
    "        ctr = True\n",
    "        for i in range(len(groups)):\n",
    "            if coll[0] in groups[i] or coll[1] in groups[i]:\n",
    "                groups[i] = groups[i]|{coll[0], coll[1]}\n",
    "                ctr = False\n",
    "        if ctr:\n",
    "            groups.append({coll[0], coll[1]})\n",
    "    return groups\n",
    "groups = get_group(colli)\n",
    "for group in groups:\n",
    "    col = 'C_'+ '_'.join(map(lambda x: str(x), list(group)))\n",
    "    train_x[col] = train_x.iloc[:,list(group)].mean(axis=1)\n",
    "    test_x[col] = test_x.iloc[:,list(group)].mean(axis=1)\n",
    "cols_drop = list()\n",
    "for group in groups:\n",
    "    cols_drop.append(train_x.columns[list(group)])\n",
    "for col in cols_drop:\n",
    "    train_x.drop(col, axis = 1, inplace=True)\n",
    "    test_x.drop(col, axis = 1, inplace=True)\n",
    "print train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "if False:\n",
    "    pca = PCA(n_components=136)\n",
    "    pca.fit(train_x)\n",
    "    train_x = pca.transform(train_x)\n",
    "    test_x = pca.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pca_cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "for i in range(200):\n",
    "    if pca_cumsum[i] > 0.95:\n",
    "        print i\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x.to_pickle('train_x.pkl')\n",
    "train_y.to_pickle('train_y.pkl')\n",
    "test_x.to_pickle('test_x.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
